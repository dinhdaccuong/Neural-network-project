{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_module.data_process as dp\n",
    "import my_module.cal_input as ci\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self,n_feature, n_hidden_l1, n_hidden_l2): #n_hidden_l1 so neural tang thu nhat\n",
    "                                                  #n_hidden_l2 so neural tang thu hai\n",
    "        super().__init__() #khoi tao\n",
    "        self.cal_hidden1 = nn.Linear(n_feature, n_hidden_l1)   #hidden layer 1\n",
    "        self.relu1 = nn.ReLU()                                 #ham kich hoat layer 1\n",
    "        self.cal_hidden2 = nn.Linear(n_hidden_l1, n_hidden_l2) #hidden layer 2\n",
    "        self.relu2 = nn.ReLU()                                 #ham kich hoat layer 2\n",
    "        self.cal_lout = nn.Linear(n_hidden_l2, 1)              #output layer\n",
    "        self.out_act = nn.Sigmoid()                #gia tri ra\n",
    "        \n",
    "    def forward(self, x_input): #forward\n",
    "        z1 = self.cal_hidden1(x_input)\n",
    "        a1 = self.relu1(z1)\n",
    "        z2 = self.cal_hidden2(a1)\n",
    "        a2 = self.relu2(z2)\n",
    "        z3 = self.cal_lout(a2)\n",
    "        y = self.out_act(z3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chuyển nhãn sang dạng 0, 1. 0-\"-\", 1-\"+\"\n",
    "#Tham số:\n",
    "    #file_name: Tên của tập chứa nhãn.\n",
    "    #num_lable: Nhãn của loại K-PTM nào - (S1, S2, S3, S4) - (1, 2, 3, 4)\n",
    "#Trả về một ma trận cột chứa nhãn dạng nhị phân của các mẫu trong file có tên file_name\n",
    "def Lable_To_Bin(file_name, num_lable): \n",
    "    path_old = os.getcwd()\n",
    "    os.chdir(\"E:\\\\WinPython-64bit-3.5.4.0Qt5\\\\notebooks\\\\Neural_Network_Final\\\\Data\\\\Train\")\n",
    "    f_read = open(file_name, \"r\")\n",
    "    \n",
    "    list_lable = [\"\", \"\", \"\", \"\"]\n",
    "    \n",
    "    #Đọc dữ liệu từ file vào list_lable\n",
    "    i = 0 #index của list_lable\n",
    "    for line in f_read:\n",
    "        list_lable[i] = \"\" + line\n",
    "        i += 1\n",
    "        \n",
    "    #Kiem tra đọc nhãn của loại nào\n",
    "    re = \"\"\n",
    "    for j in range(4):\n",
    "        if((num_lable) == j):\n",
    "            re = list_lable[j]\n",
    "    re = re[0: len(re)-1] #Bo ki tu xuong dong\n",
    "    \n",
    "    #Chuyển nhãn của dữ liệu về ma trận cột dạng nhị phân\n",
    "    matrix_b = np.ones((len(re), 1))\n",
    "    k = 0 #chi so hang cua matrix_b\n",
    "    for ch in re:\n",
    "        if(ch == \"+\"):\n",
    "            matrix_b[k][0] = 1\n",
    "        else:\n",
    "            matrix_b[k][0] = 0\n",
    "        k += 1\n",
    "    os.chdir(path_old)\n",
    "    f_read.close()\n",
    "    return matrix_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lớp chứa dữ liệu đầu vào cho mạng\n",
    "#Tham số của hàm khởi tạo:\n",
    "    #num_s: Tính xác xuất trên tập s1 or s2 or s3 or s3, num_s = (0, 1, 2, 3)\n",
    "#Các thuộc tính:\n",
    "    #list_pro: List chứa xác xuất đầu vào cho mạng.\n",
    "    #list_lable_bin: List chứa các ma trận cột là nhãn đã chuyển về dạng nhị phân của 5 tập dữ liệu.\n",
    "    #input_train: Đầu vào cho tập train\n",
    "    #input_val: Đầu vào cho tập val\n",
    "    #lable_train: Nhãn của tập train\n",
    "    #lable_val: Nhãn của tập val\n",
    "    #self.lable: Nhãn của toàn bộ tập dữ liệu\n",
    "class ModelData:\n",
    "    path_train = \"E:\\\\WinPython-64bit-3.5.4.0Qt5\\\\notebooks\\\\Neural_Network_Final\\\\Data\\\\Train\"\n",
    "    path_pro = \"E:\\\\WinPython-64bit-3.5.4.0Qt5\\\\notebooks\\\\Neural_Network_Final\\\\Data\\\\K_PTM\"\n",
    "        \n",
    "    list_pos_name = [\"s1_pos.txt\", \"s2_pos.txt\", \"s3_pos.txt\", \"s4_pos.txt\"]\n",
    "    list_neg_name = [\"s1_neg.txt\", \"s3_neg.txt\", \"s3_neg.txt\", \"s4_neg.txt\"]\n",
    "        \n",
    "    list_data_name = [\"data1.txt\", \"data2.txt\", \"data3.txt\", \"data4.txt\", \"data5.txt\"]\n",
    "    list_lable_name = [\"lable1.txt\", \"lable2.txt\", \"lable3.txt\", \"lable4.txt\", \"lable5.txt\"]\n",
    "    \n",
    "    def __init__(self, num_s): #num_s: 0, 1, 2, 3\n",
    "        self.num_s = num_s\n",
    "        self.list_pro = []    #Lưu các xác xuất của tập 1 -> 5\n",
    "        self.list_lable_bin = []\n",
    "    def __Cal_Pro(self):    #Tính xác xuất của 5 tập đối với loại K-PTM S_num_s     \n",
    "        for i in range(4):\n",
    "            if(i == (self.num_s)):  #Tinh xac suat doi voi tap num_s\n",
    "                for j in range(5):\n",
    "                    pro_o = ci.Probability(self.path_train,self.list_data_name[j], self.list_pos_name[i], self.list_neg_name[i], self.path_pro)\n",
    "                    self.list_pro.append(pro_o.Cal_Probability())\n",
    "    def __Lable(self):  #Chuyen cac nhan sang danh nhi phan va luu cac thuoc tinh\n",
    "        for i in range(5):\n",
    "            self.list_lable_bin.append(Lable_To_Bin(self.list_lable_name[i], self.num_s))\n",
    "        #Gộp tất cả các nhãn của cả 5 tập dữ liệu với nhau:\n",
    "        self.lable = self.list_lable_bin[0]\n",
    "        for i in range(1, 5):\n",
    "            self.lable = np.concatenate((self.lable, self.list_lable_bin[i]), axis = 0)\n",
    "            \n",
    "    def Active(self):\n",
    "        self.__Cal_Pro()  #Tinh xác xuat\n",
    "        self.__Lable()    #Chuyển nhãn sang dạng nhị phân\n",
    "    def Train_And_Val(self, s):    #Ex: s = 0 - Tập data1 là tập val, còn lại gộp lại là tập train\n",
    "        flag = 0\n",
    "        for j in range(5):\n",
    "            if((j != s) & (flag == 0)):\n",
    "                self.input_train = self.list_pro[j]\n",
    "                self.lable_train = self.list_lable_bin[j]\n",
    "                flag = 1\n",
    "            elif(j != s):\n",
    "                self.input_train = np.concatenate((self.input_train, self.list_pro[j]), axis = 0)\n",
    "                self.lable_train = np.concatenate((self.lable_train, self.list_lable_bin[j]), axis = 0)\n",
    "                \n",
    "        self.input_val = self.list_pro[s]\n",
    "        self.lable_val = self.list_lable_bin[s]\n",
    "        #Gộp ma trận nhãn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thuộc tính:\n",
    "    #net_num: mạng training cho loại K-PTM Snet_num, tính xác xuất trên Snet_num, net_num = (0, 1, 2, 3)\n",
    "    #n_hidden_l1: Số neural tầng thứ nhất\n",
    "    #n_hidden_l2: Số neural tầng thứ hai\n",
    "class Model:\n",
    "    Result = []   #Kết quả dự đoán - Thuộc tính lớp\n",
    "    Lable  = []   #Nhãn của dữ liệu - thuộc tính Lớp\n",
    "    def __init__(self, data, net_num, n_hidden_l1, n_hidden_l2):\n",
    "        self.net_num = net_num\n",
    "        self.n_hidden_l1 = n_hidden_l1\n",
    "        self.n_hidden_l2 = n_hidden_l2\n",
    "        self.predicted = np.zeros((6393, 1))\n",
    "        self.data = data\n",
    "        \n",
    "    def Train_And_Predict(self):\n",
    "        k = 0\n",
    "        self.Result.append(np.zeros((6393, 1)))#Mỗi lần gọi hàm sẽ khởi tạo cho list kết quả ở lần đó một ma trận 0, sau đó gán sau\n",
    "        self.Lable.append(self.data.lable)     #thêm nhãn của tập dữ liệu hiện tại.\n",
    "        for i_data in range(5): #i_data = 0 - dung tap data1 lam tap val\n",
    "            count = 0\n",
    "            net = Neural_Network(26, self.n_hidden_l1, self.n_hidden_l2)\n",
    "            opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "            criterion = nn.BCELoss()\n",
    "            \n",
    "            self.data.Train_And_Val(i_data)  #Tính dữ liệu vào train và test\n",
    "            input_net = torch.from_numpy(self.data.input_train).type(torch.FloatTensor)\n",
    "            lable_net = torch.from_numpy(self.data.lable_train).type(torch.FloatTensor)\n",
    "            net.train()\n",
    "            for t in range(1000):\n",
    "                opt.zero_grad()                     #Xoa gradient cho lan train tiep theo\n",
    "                y_hat = net(input_net)              #tinh output\n",
    "                loss = criterion(y_hat, lable_net)  #tinh loi\n",
    "                loss.backward()                     #tinh gradinet\n",
    "                opt.step()\n",
    "                \n",
    "            #Predict\n",
    "            input_val = torch.from_numpy(self.data.input_val).type(torch.FloatTensor)\n",
    "            net.eval()\n",
    "            outputs = net(input_val).data.numpy()  #Tính output của mạng với tập val sau khi train\n",
    "            for i in range(outputs.shape[0]):\n",
    "                if(outputs[i][0] >= 0.5):\n",
    "                    self.Result[self.net_num][k][0] = 1  #Gán dữ liệu tính được vào tập Result\n",
    "                elif(outputs[i][0] < 0.5):\n",
    "                    self.Result[self.net_num][k][0] = 0  #Gán dữ liệu tính được vào tập Result\n",
    "                k += 1   \n",
    "                \n",
    "                if((outputs[i][0] >= 0.5) & (self.data.lable_val[i][0] == 1) | (outputs[i][0] < 0.5) & (self.data.lable_val[i][0] == 0)):\n",
    "                    count += 1\n",
    "            prob = count*100/outputs.shape[0]\n",
    "            print(\"predict_data%s\" % (i_data), prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasuringMetrics:\n",
    "    def __init__(self, predict_data, lable_data):\n",
    "        self.predict_data = predict_data\n",
    "        self.lable_data = lable_data\n",
    "        self.Aming = 0\n",
    "        self.Coverage = 0\n",
    "        self.Accuracy = 0\n",
    "        #######\n",
    "    def Cal(self):\n",
    "        #Yk Nhãn đã được quan sát thử nghiệm\n",
    "        #Zk Nhãn dự đoán bằng mô hình mạng\n",
    "        total_sample = 6393\n",
    "        count = 0\n",
    "        for i_sample in range(6393):  #List có 4 phần tử tương úng với 4 loại K-PTM\n",
    "            Yk_inter_Zk = 0\n",
    "            Yk_uni_Zk = 0\n",
    "            Yk = 0\n",
    "            Zk = 0\n",
    "            for i_list in range(4):\n",
    "                if((self.predict_data[i_list][i_sample][0]==1) & (self.lable_data[i_list][i_sample][0]==1)):\n",
    "                    Yk_inter_Zk += 1\n",
    "                if(self.predict_data[i_list][i_sample][0]==1):\n",
    "                    Zk += 1\n",
    "                if(self.lable_data[i_list][i_sample][0]==1):\n",
    "                    Yk += 1\n",
    "            if((Yk == 0) & (Zk == 0)):\n",
    "                Yk_inter_Zk = 1\n",
    "            if(Yk == 0):\n",
    "                Yk = 1\n",
    "            if(Zk == 0):\n",
    "                Zk = 1\n",
    "                \n",
    "            Yk_uni_Zk = Zk + Yk - Yk_inter_Zk\n",
    "#             print(\"Yk: \", Yk)\n",
    "#             print(\"Zk: \", Zk)\n",
    "#             print(\"Yk_inter_Zk: \", Yk_inter_Zk)\n",
    "            self.Aming += Yk_inter_Zk/Zk\n",
    "            self.Coverage += Yk_inter_Zk/Yk\n",
    "            self.Accuracy += Yk_inter_Zk/Yk_uni_Zk       \n",
    "        self.Aming = self.Aming/total_sample\n",
    "        self.Coverage = self.Coverage/total_sample\n",
    "        self.Accuracy = self.Accuracy/total_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = ModelData(0)\n",
    "data1 = ModelData(1)\n",
    "data2 = ModelData(2)\n",
    "data3 = ModelData(3)\n",
    "\n",
    "data0.Active()\n",
    "data1.Active()\n",
    "data2.Active()\n",
    "data3.Active()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = Model(data0, 0, 64, 32)\n",
    "model1 = Model(data1, 1, 64, 32)\n",
    "model2 = Model(data2, 2, 64, 32)\n",
    "model3 = Model(data3, 3, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_data0 86.85446009389672\n",
      "predict_data1 87.32394366197182\n",
      "predict_data2 88.96713615023474\n",
      "predict_data3 87.7151799687011\n",
      "predict_data4 89.14910226385636\n",
      "predict_data0 99.37402190923318\n",
      "predict_data1 99.92175273865415\n",
      "predict_data2 98.74804381846636\n",
      "predict_data3 100.0\n",
      "predict_data4 100.0\n",
      "predict_data0 99.76525821596245\n",
      "predict_data1 99.8435054773083\n",
      "predict_data2 99.76525821596245\n",
      "predict_data3 99.8435054773083\n",
      "predict_data4 100.0\n",
      "predict_data0 90.06259780907668\n",
      "predict_data1 94.5226917057903\n",
      "predict_data2 93.74021909233177\n",
      "predict_data3 95.46165884194053\n",
      "predict_data4 94.53551912568307\n"
     ]
    }
   ],
   "source": [
    "model0.Train_And_Predict()\n",
    "model1.Train_And_Predict()\n",
    "model2.Train_And_Predict()\n",
    "model3.Train_And_Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aming   :  0.8700401480786276\n",
      "Coverage:  0.8708743938682935\n",
      "Accuracy:  0.8555711976641117\n"
     ]
    }
   ],
   "source": [
    "# print(Model.Result[3])\n",
    "me = MeasuringMetrics(Model.Result, Model.Lable)\n",
    "me.Cal()\n",
    "print(\"Aming   : \",me.Aming)\n",
    "print(\"Coverage: \",me.Coverage)\n",
    "print(\"Accuracy: \",me.Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  1.  0.  0.]\n",
      " [ 1.  1.  0.  0.]\n",
      " [ 1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  1.  0.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  1.  1.  0.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "a1 = Model.Result\n",
    "a2 = Model.Lable\n",
    "\n",
    "x = np.concatenate((a1[0], a1[1], a1[2], a1[3]), axis = 1)\n",
    "print(x[0:200, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((a2[0], a2[1], a2[2], a2[3]), axis = 1)\n",
    "print(y[0:30, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(data, 0, 64, 32)\n",
    "model1.Train_And_Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model1.data.list_lable_bin[0]\n",
    "for i in range(1, 5):\n",
    "    a = np.concatenate((a, model1.data.list_lable_bin[i]), axis = 0)\n",
    "count = 0\n",
    "for j in range(a.shape[0]):\n",
    "    if(Model.Result[0][j][0] == a[j][0]):\n",
    "        count += 1\n",
    "print(\"probability: \", count*100/a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_Network(26, 64, 32)\n",
    "opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(model, i_test, re_test):\n",
    "    model.eval()\n",
    "    count_t = 0\n",
    "    outputs = net(i_test)\n",
    "    outputs = outputs.data.numpy()\n",
    "    print(\"output: \")\n",
    "    print(outputs)\n",
    "    re_test1 = re_test.data.numpy()\n",
    "    for i in range(i_test.shape[0]):\n",
    "        if(((outputs[i][0] >= 0.5) & (re_test1[i][0] == 1.)) | ((outputs[i][0] < 0.5) & (re_test1[i][0] == 0.))):\n",
    "            count_t += 1\n",
    "            \n",
    "    return count_t/i_test.shape[0] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(x_input, re_input, model, op, cri):\n",
    "    loss_list = []\n",
    "    for t in range(5000):\n",
    "        op.zero_grad()  #Xoa gradient cho lan train tiep theo\n",
    "        y_hat = net(x_input) #tinh output\n",
    "        loss = cri(y_hat, re_input)  #tinh loi\n",
    "        loss.backward()   #tinh gradinet\n",
    "        opt.step()        #cap nhat trong so\n",
    "        loss_list.append(loss.data.numpy())\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4]\n",
      " [5 8 9]\n",
      " [2 4 5]\n",
      " [8 9 0]\n",
      " [6 8 3]\n",
      " [4 8 9]]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.array([[1, 2, 4],\n",
    "               [5, 6, 7]])\n",
    "a2 = np.array([[2, 3, 4],\n",
    "               [5, 8, 9]])\n",
    "a3 = np.array([[2, 4, 5], \n",
    "               [8, 9, 0]])\n",
    "a4 = np.array([[6, 8, 3],\n",
    "               [4, 8, 9]])\n",
    "list_matrix = [a1, a2, a3, a4]\n",
    "dec = 0\n",
    "i = 0; #Không gộp a4\n",
    "for j in range(4):\n",
    "    if((j != i) & (dec == 0)):\n",
    "        a = list_matrix[j]\n",
    "        dec = 1\n",
    "    elif(j != i):\n",
    "        a = np.concatenate((a, list_matrix[j]), axis = 0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "tensor([2., 4., 5.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([2, 4, 5])\n",
    "c = a.type(torch.DoubleTensor)\n",
    "print(a.type())\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eefbcad400>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7iIiEaRwFxGJoP8PK/C/UrfPtXwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eefbf68b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = Train(input_1, result_1, net, opt, criterion)\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
